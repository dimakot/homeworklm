{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b48029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‡Ğ°Ñ‚Ğ° Ñ MCP\n",
    "# await chat_with_llms_and_mcp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b65e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "\n",
    "from mcp import ClientSession\n",
    "from mcp.client.stdio import StdioServerParameters, stdio_client\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "console = Console()\n",
    "\n",
    "# ĞŸÑƒÑ‚ÑŒ Ğº Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾ ÑĞ¾Ğ±Ñ€Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ MCP ÑĞµÑ€Ğ²ĞµÑ€Ñƒ Airbnb\n",
    "MCP_SERVER_PATH = os.path.join(\n",
    "    \"/Users\",\n",
    "    \"dmitriikot\",\n",
    "    \"Documents\",\n",
    "    \"lectures\",\n",
    "    \"HomeWork\",\n",
    "    \"9_api\",\n",
    "    \"mcp-server-airbnb\",\n",
    "    \"dist\",\n",
    "    \"index.js\",\n",
    ")\n",
    "\n",
    "\n",
    "class MCPToolManager:\n",
    "    \"\"\"Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸ĞµĞ¼ Ğº MCP ÑĞµÑ€Ğ²ĞµÑ€Ñƒ Ğ¸ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ°Ğ¼Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ².\"\"\"\n",
    "\n",
    "    def __init__(self, command: str, args: List[str]):\n",
    "        self.command = command\n",
    "        self.args = args\n",
    "        self._stdio_context = None\n",
    "        self._session = None\n",
    "        self._cached_tools = None\n",
    "\n",
    "    async def connect(self) -> None:\n",
    "        if self._session is not None:\n",
    "            return\n",
    "\n",
    "        params = StdioServerParameters(command=self.command, args=self.args)\n",
    "        self._stdio_context = stdio_client(params)\n",
    "        read_stream, write_stream = await self._stdio_context.__aenter__()\n",
    "        \n",
    "        self._session = ClientSession(read_stream, write_stream)\n",
    "        await self._session.__aenter__()\n",
    "        \n",
    "        init_result = await self._session.initialize()\n",
    "        try:\n",
    "            server_info = getattr(init_result, 'serverInfo', None)\n",
    "            if server_info:\n",
    "                server_name = getattr(server_info, 'name', 'MCP Server')\n",
    "                server_version = getattr(server_info, 'version', 'unknown')\n",
    "                console.print(f\"[dim]MCP ÑĞµÑ€Ğ²ĞµÑ€ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½: {server_name} v{server_version}[/dim]\")\n",
    "        except Exception:\n",
    "            console.print(\"[dim]MCP ÑĞµÑ€Ğ²ĞµÑ€ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½[/dim]\")\n",
    "        self._cached_tools = None\n",
    "\n",
    "    async def list_tools(self):\n",
    "        await self.connect()\n",
    "        if self._cached_tools is None:\n",
    "            self._cached_tools = await self._session.list_tools()\n",
    "        return self._cached_tools\n",
    "\n",
    "    async def get_langchain_tools(self) -> List[Dict[str, Any]]:\n",
    "        tools = await self.list_tools()\n",
    "        langchain_tools: List[Dict[str, Any]] = []\n",
    "        for tool in tools.tools:\n",
    "            schema = tool.inputSchema or {\"type\": \"object\", \"properties\": {}}\n",
    "            langchain_tools.append(\n",
    "                {\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": tool.name,\n",
    "                        \"description\": tool.description or \"\",\n",
    "                        \"parameters\": schema,\n",
    "                    },\n",
    "                }\n",
    "            )\n",
    "        return langchain_tools\n",
    "\n",
    "    async def call_tool(self, name: str, arguments: Dict[str, Any]) -> Any:\n",
    "        await self.connect()\n",
    "        return await self._session.call_tool(name, arguments)\n",
    "\n",
    "    async def close(self) -> None:\n",
    "        if self._session:\n",
    "            try:\n",
    "                await self._session.__aexit__(None, None, None)\n",
    "            except Exception:\n",
    "                pass\n",
    "            self._session = None\n",
    "        if self._stdio_context:\n",
    "            try:\n",
    "                await self._stdio_context.__aexit__(None, None, None)\n",
    "            except Exception:\n",
    "                pass\n",
    "            self._stdio_context = None\n",
    "        self._cached_tools = None\n",
    "\n",
    "\n",
    "def format_tool_result(result: Any) -> str:\n",
    "    \"\"\"ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµÑ‚ MCP Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ² ÑÑ‚Ñ€Ğ¾ĞºÑƒ Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸.\"\"\"\n",
    "    if getattr(result, \"structuredContent\", None):\n",
    "        try:\n",
    "            return json.dumps(result.structuredContent, ensure_ascii=False, indent=2)\n",
    "        except (TypeError, ValueError):\n",
    "            return str(result.structuredContent)\n",
    "\n",
    "    text_chunks: List[str] = []\n",
    "    if getattr(result, \"content\", None):\n",
    "        for block in result.content:\n",
    "            text = getattr(block, \"text\", None) or block.get(\"text\") if isinstance(block, dict) else None\n",
    "            if text:\n",
    "                text_chunks.append(text)\n",
    "    if text_chunks:\n",
    "        return \"\\n\".join(text_chunks)\n",
    "\n",
    "    return str(result)\n",
    "\n",
    "\n",
    "def get_llm_clients() -> Dict[str, ChatOpenAI]:\n",
    "    llm1 = ChatOpenAI(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        model=\"Qwen/Qwen3-Next-80B-A3B-Instruct\",\n",
    "    )\n",
    "\n",
    "    llm2 = ChatOpenAI(\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        model=\"GigaChat/GigaChat-2-Max\",\n",
    "    )\n",
    "\n",
    "    return {\"llm1\": llm1, \"llm2\": llm2}\n",
    "\n",
    "\n",
    "def test_llms() -> None:\n",
    "    llms = get_llm_clients()\n",
    "\n",
    "    console.print(Panel(\"[bold cyan]Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ²ÑƒÑ… LLM[/bold cyan]\", border_style=\"cyan\"))\n",
    "\n",
    "    test_messages = [\n",
    "        SystemMessage(content=\"Ğ¢Ñ‹ Ğ¾Ñ‡ĞµĞ½ÑŒ Ñ…Ğ¾Ñ‡ĞµÑˆÑŒ Ğ²ÑĞµĞ¼ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ÑŒ\"),\n",
    "        HumanMessage(content=\"ĞŸÑ€Ğ¸Ğ²ĞµÑ‚!\"),\n",
    "    ]\n",
    "\n",
    "    console.print(\"\\n[bold yellow]LLM 1:[/bold yellow]\")\n",
    "    response1 = llms[\"llm1\"].invoke(test_messages)\n",
    "    console.print(Markdown(response1.content))\n",
    "\n",
    "    console.print(\"\\n[bold yellow]LLM 2:[/bold yellow]\")\n",
    "    response2 = llms[\"llm2\"].invoke(test_messages)\n",
    "    console.print(Markdown(response2.content))\n",
    "\n",
    "\n",
    "async def chat_with_llms_and_mcp() -> None:\n",
    "    \"\"\"ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚ Ñ LLM Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ MCP Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸.\"\"\"\n",
    "    llms = get_llm_clients()\n",
    "    active_llm = \"llm2\"\n",
    "\n",
    "    mcp_manager = MCPToolManager(\n",
    "        command=\"node\",\n",
    "        args=[MCP_SERVER_PATH, \"--ignore-robots-txt\"],\n",
    "    )\n",
    "    console.print(\"[dim]ĞŸÑ€Ğ¾Ğ±ÑƒÑ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº MCP ÑĞµÑ€Ğ²ĞµÑ€Ñƒ...[/dim]\")\n",
    "\n",
    "    try:\n",
    "        langchain_tools = await asyncio.wait_for(\n",
    "            mcp_manager.get_langchain_tools(),\n",
    "            timeout=30,\n",
    "        )\n",
    "        mcp_enabled = True\n",
    "        console.print(\n",
    "            Panel(\n",
    "                f\"[bold green]ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² MCP: {len(langchain_tools)}[/bold green]\",\n",
    "                border_style=\"green\",\n",
    "            )\n",
    "        )\n",
    "    except asyncio.TimeoutError:\n",
    "        await mcp_manager.close()\n",
    "        console.print(\n",
    "            Panel(\n",
    "                \"[bold yellow]MCP Ğ½Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½: Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ[/bold yellow]\",\n",
    "                border_style=\"yellow\",\n",
    "            )\n",
    "        )\n",
    "        langchain_tools = []\n",
    "        mcp_enabled = False\n",
    "    except Exception as e:\n",
    "        await mcp_manager.close()\n",
    "        console.print(\n",
    "            Panel(\n",
    "                f\"[bold yellow]MCP Ğ½Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½: {str(e)}[/bold yellow]\",\n",
    "                border_style=\"yellow\",\n",
    "            )\n",
    "        )\n",
    "        langchain_tools = []\n",
    "        mcp_enabled = False\n",
    "\n",
    "    history: Dict[str, List[AIMessage | HumanMessage | SystemMessage | ToolMessage]] = {\n",
    "        \"llm1\": [SystemMessage(content=\"Ğ¢Ñ‹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ¾Ğ¼ Ğº Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼ Airbnb\")],\n",
    "        \"llm2\": [SystemMessage(content=\"Ğ¢Ñ‹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚ Ñ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ¾Ğ¼ Ğº Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼ Airbnb\")],\n",
    "    }\n",
    "\n",
    "    runnable_cache: Dict[str, Any] = {}\n",
    "    if mcp_enabled and langchain_tools:\n",
    "        console.print(\"[dim]ĞŸÑ€Ğ¸Ğ²ÑĞ·Ñ‹Ğ²Ğ°Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğº Ğ¾Ğ±ĞµĞ¸Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼...[/dim]\")\n",
    "        runnable_cache[\"llm1\"] = llms[\"llm1\"].bind_tools(langchain_tools)\n",
    "        runnable_cache[\"llm2\"] = llms[\"llm2\"].bind_tools(langchain_tools)\n",
    "        console.print(\"[dim]ĞĞ±Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹ Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸[/dim]\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            user_input = await asyncio.to_thread(input, f\"\\n({active_llm}) Ğ’Ñ‹: \")\n",
    "\n",
    "            if not user_input.strip():\n",
    "                continue\n",
    "\n",
    "            if user_input.strip() == \"/exit\":\n",
    "                console.print(\"[bold red]Ğ“ÑƒĞ´Ğ±Ğ°Ğ¹[/bold red]\")\n",
    "                break\n",
    "\n",
    "            if user_input.strip() == \"/swap\":\n",
    "                active_llm = \"llm2\" if active_llm == \"llm1\" else \"llm1\"\n",
    "                console.print(f\"[bold cyan]ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¾ Ğ½Ğ° {active_llm}[/bold cyan]\")\n",
    "                continue\n",
    "\n",
    "            if user_input.strip() == \"/clear\":\n",
    "                for key in history:\n",
    "                    system_msg = history[key][0]\n",
    "                    history[key] = [system_msg]\n",
    "                console.print(\"[bold yellow]Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ°[/bold yellow]\")\n",
    "                continue\n",
    "\n",
    "            if user_input.strip() == \"/model\":\n",
    "                console.print(f\"[bold cyan]ĞĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {active_llm}[/bold cyan]\")\n",
    "                console.print(f\"[dim]MCP {'Ğ²ĞºĞ»ÑÑ‡ĞµĞ½' if mcp_enabled else 'Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½'}[/dim]\")\n",
    "                continue\n",
    "\n",
    "            if user_input.strip() == \"/tools\":\n",
    "                if mcp_enabled:\n",
    "                    tools_info = await mcp_manager.list_tools()\n",
    "                    console.print(\"[bold cyan]Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ MCP Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹:[/bold cyan]\")\n",
    "                    for tool in tools_info.tools:\n",
    "                        console.print(f\"  â€¢ {tool.name}: {tool.description}\")\n",
    "                else:\n",
    "                    console.print(\"[yellow]MCP Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹[/yellow]\")\n",
    "                continue\n",
    "\n",
    "            history[active_llm].append(HumanMessage(content=user_input))\n",
    "            console.print(f\"[dim]({active_llm}) Ğ´ÑƒĞ¼Ğ°Ñ...[/dim]\")\n",
    "\n",
    "            if mcp_enabled and langchain_tools and active_llm in runnable_cache:\n",
    "                response: AIMessage = await runnable_cache[active_llm].ainvoke(history[active_llm])\n",
    "            else:\n",
    "                response = await llms[active_llm].ainvoke(history[active_llm])\n",
    "\n",
    "            if getattr(response, \"tool_calls\", None):\n",
    "                console.print(\"[bold magenta]ğŸ”§ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹...[/bold magenta]\")\n",
    "                history[active_llm].append(response)\n",
    "\n",
    "                for tool_call in response.tool_calls:\n",
    "                    tool_name = tool_call[\"name\"]\n",
    "                    tool_args = tool_call.get(\"args\", {}) or {}\n",
    "                    console.print(f\"[yellow]Ğ’Ñ‹Ğ·Ğ¾Ğ²: {tool_name}({tool_args})[/yellow]\")\n",
    "\n",
    "                    try:\n",
    "                        tool_result = await mcp_manager.call_tool(tool_name, tool_args)\n",
    "                        rendered = format_tool_result(tool_result)\n",
    "                        console.print(f\"[dim]Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ MCP:[/dim]\\n{rendered}\")\n",
    "                    except Exception as tool_error:\n",
    "                        rendered = f\"ĞÑˆĞ¸Ğ±ĞºĞ° MCP: {tool_error}\"\n",
    "                        console.print(f\"[bold red]{rendered}[/bold red]\")\n",
    "\n",
    "                    history[active_llm].append(\n",
    "                        ToolMessage(content=rendered, tool_call_id=tool_call[\"id\"])\n",
    "                    )\n",
    "\n",
    "                console.print(f\"[dim]({active_llm}) Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒÑ Ğ¾Ñ‚Ğ²ĞµÑ‚...[/dim]\")\n",
    "                final_response = await llms[active_llm].ainvoke(history[active_llm])\n",
    "                history[active_llm].append(final_response)\n",
    "                console.print(Markdown(final_response.content))\n",
    "            else:\n",
    "                history[active_llm].append(response)\n",
    "                console.print(Markdown(response.content))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        console.print(\"\\n[bold yellow]Ğ“ÑƒĞ´Ğ±Ğ°Ğ¹[/bold yellow]\")\n",
    "    finally:\n",
    "        await mcp_manager.close()\n",
    "\n",
    "\n",
    "def chat_with_llms() -> None:\n",
    "    \"\"\"Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚ Ğ±ĞµĞ· MCP Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ².\"\"\"\n",
    "    llms = get_llm_clients()\n",
    "    active_llm = \"llm1\"\n",
    "\n",
    "    history: Dict[str, List[AIMessage | HumanMessage | SystemMessage | ToolMessage]] = {\n",
    "        \"llm1\": [SystemMessage(content=\"Ğ¢Ñ‹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚\")],\n",
    "        \"llm2\": [SystemMessage(content=\"Ğ¢Ñ‹ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚\")],\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(f\"\\n({active_llm}) Ğ’Ñ‹: \")\n",
    "\n",
    "            if not user_input.strip():\n",
    "                continue\n",
    "\n",
    "            if user_input.strip() == \"/exit\":\n",
    "                console.print(\"[bold red]Ğ“ÑƒĞ´Ğ±Ğ°Ğ¹[/bold red]\")\n",
    "                break\n",
    "\n",
    "            if user_input.strip() == \"/swap\":\n",
    "                active_llm = \"llm2\" if active_llm == \"llm1\" else \"llm1\"\n",
    "                console.print(f\"[bold cyan]ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¾ Ğ½Ğ° {active_llm}[/bold cyan]\")\n",
    "                continue\n",
    "\n",
    "            if user_input.strip() == \"/clear\":\n",
    "                for key in history:\n",
    "                    system_msg = history[key][0]\n",
    "                    history[key] = [system_msg]\n",
    "                console.print(\"[bold yellow]Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ°[/bold yellow]\")\n",
    "                continue\n",
    "\n",
    "            if user_input.strip() == \"/model\":\n",
    "                console.print(f\"[bold cyan]ĞĞºÑ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {active_llm}[/bold cyan]\")\n",
    "                continue\n",
    "\n",
    "            history[active_llm].append(HumanMessage(content=user_input))\n",
    "            console.print(f\"[dim]({active_llm}) Ğ´ÑƒĞ¼Ğ°Ñ...[/dim]\")\n",
    "\n",
    "            response = llms[active_llm].invoke(history[active_llm])\n",
    "            history[active_llm].append(response)\n",
    "\n",
    "            console.print(Markdown(response.content))\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            console.print(\"\\n[bold yellow]Ğ“ÑƒĞ´Ğ±Ğ°Ğ¹[/bold yellow]\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            console.print(f\"[bold red]ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)}[/bold red]\")\n",
    "            import traceback\n",
    "            console.print(f\"[dim]{traceback.format_exc()}[/dim]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "474df840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ĞŸÑ€Ğ¾Ğ±ÑƒÑ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº MCP ÑĞµÑ€Ğ²ĞµÑ€Ñƒ</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mĞŸÑ€Ğ¾Ğ±ÑƒÑ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğº MCP ÑĞµÑ€Ğ²ĞµÑ€Ñƒ\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">MCP ÑĞµÑ€Ğ²ĞµÑ€ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½: airbnb v0.</span><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf; font-weight: bold\">1.3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mMCP ÑĞµÑ€Ğ²ĞµÑ€ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½: airbnb v0.\u001b[0m\u001b[1;2;36m1.3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² MCP: 2</span>                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">â”‚</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mâ•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®\u001b[0m\n",
       "\u001b[32mâ”‚\u001b[0m \u001b[1;32mĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² MCP: 2\u001b[0m                                                                                  \u001b[32mâ”‚\u001b[0m\n",
       "\u001b[32mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ĞŸÑ€Ğ¸Ğ²ÑĞ·Ñ‹Ğ²Ğ°Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğº Ğ¾Ğ±ĞµĞ¸Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mĞŸÑ€Ğ¸Ğ²ÑĞ·Ñ‹Ğ²Ğ°Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğº Ğ¾Ğ±ĞµĞ¸Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">ĞĞ±Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹ Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2mĞĞ±Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹ Ğº Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm2</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Ğ´ÑƒĞ¼Ğ°Ñ</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2m(\u001b[0m\u001b[2mllm2\u001b[0m\u001b[1;2m)\u001b[0m\u001b[2m Ğ´ÑƒĞ¼Ğ°Ñ\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ñ‚ÑŒ Ğ½Ğ° Ğ²Ğ°Ñˆ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ.                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ğ˜Ğ·Ğ²Ğ¸Ğ½Ğ¸Ñ‚Ğµ, Ğ½Ğµ Ğ¼Ğ¾Ğ³Ñƒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ñ‚ÑŒ Ğ½Ğ° Ğ²Ğ°Ñˆ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ.                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm2</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Ğ´ÑƒĞ¼Ğ°Ñ</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2m(\u001b[0m\u001b[2mllm2\u001b[0m\u001b[1;2m)\u001b[0m\u001b[2m Ğ´ÑƒĞ¼Ğ°Ñ\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ğ•ÑĞ»Ğ¸ Ñƒ Ğ²Ğ°Ñ ĞµÑÑ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸Ğ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ° Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ, Ğ¾Ğ±Ñ€Ğ°Ñ‰Ğ°Ğ¹Ñ‚ĞµÑÑŒ! Ğ”Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ!                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ğ•ÑĞ»Ğ¸ Ñƒ Ğ²Ğ°Ñ ĞµÑÑ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¸Ğ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ° Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ, Ğ¾Ğ±Ñ€Ğ°Ñ‰Ğ°Ğ¹Ñ‚ĞµÑÑŒ! Ğ”Ğ¾ ÑĞ²Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ!                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm2</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Ğ´ÑƒĞ¼Ğ°Ñ</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2m(\u001b[0m\u001b[2mllm2\u001b[0m\u001b[1;2m)\u001b[0m\u001b[2m Ğ´ÑƒĞ¼Ğ°Ñ\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ğ’ÑĞµĞ³Ğ¾ Ğ´Ğ¾Ğ±Ñ€Ğ¾Ğ³Ğ¾! ĞĞ±Ñ€Ğ°Ñ‰Ğ°Ğ¹Ñ‚ĞµÑÑŒ, ĞµÑĞ»Ğ¸ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ.                                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ğ’ÑĞµĞ³Ğ¾ Ğ´Ğ¾Ğ±Ñ€Ğ¾Ğ³Ğ¾! ĞĞ±Ñ€Ğ°Ñ‰Ğ°Ğ¹Ñ‚ĞµÑÑŒ, ĞµÑĞ»Ğ¸ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ.                                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">llm2</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">)</span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> Ğ´ÑƒĞ¼Ğ°Ñ</span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;2m(\u001b[0m\u001b[2mllm2\u001b[0m\u001b[1;2m)\u001b[0m\u001b[2m Ğ´ÑƒĞ¼Ğ°Ñ\u001b[0m\u001b[2;33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ĞŸÑ€Ğ¾Ñ‰Ğ°Ğ¹Ñ‚Ğµ! Ğ•ÑĞ»Ğ¸ Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ½ÑƒÑ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ² Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞ¼ â€” Ñ Ğ·Ğ´ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ Ğ²Ğ°Ğ¼.                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "ĞŸÑ€Ğ¾Ñ‰Ğ°Ğ¹Ñ‚Ğµ! Ğ•ÑĞ»Ğ¸ Ğ²Ğ¾Ğ·Ğ½Ğ¸ĞºĞ½ÑƒÑ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ² Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞ¼ â€” Ñ Ğ·Ğ´ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ Ğ²Ğ°Ğ¼.                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# await chat_with_llms()\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m chat_with_llms_and_mcp()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 224\u001b[39m, in \u001b[36mchat_with_llms_and_mcp\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m         user_input = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.to_thread(\u001b[38;5;28minput\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactive_llm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) Ğ’Ñ‹: \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    226\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_input.strip():\n\u001b[32m    227\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.13.7-macos-aarch64-none/lib/python3.13/asyncio/threads.py:25\u001b[39m, in \u001b[36mto_thread\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     23\u001b[39m ctx = contextvars.copy_context()\n\u001b[32m     24\u001b[39m func_call = functools.partial(ctx.run, func, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.run_in_executor(\u001b[38;5;28;01mNone\u001b[39;00m, func_call)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# await chat_with_llms()\n",
    "await chat_with_llms_and_mcp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HomeWork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
